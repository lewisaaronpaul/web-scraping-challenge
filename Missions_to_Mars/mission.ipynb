{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest_news_title:   NASA, ULA Launch Mars 2020 Perseverance Rover Mission to Red Planet\n",
      "latest_news_p:   The agency's Mars 2020 mission is on its way. It will land at Jezero Crater in about seven months, on Feb. 18, 2021. \n",
      "featured_image_url:   https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA12826_hires.jpg\n",
      "mars_weather:   InSight sol 597 (2020-08-01) low -91.0ºC (-131.8ºF) high -16.9ºC (1.6ºF)\n",
      "winds from the WNW at 8.0 m/s (17.9 mph) gusting to 20.2 m/s (45.1 mph)\n",
      "pressure at 7.90 hPa\n",
      "cerberus_title:   Cerberus Hemisphere\n",
      "cerberus_img_url:   https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg\n",
      "schiaparelli_title:   Schiaparelli Hemisphere\n",
      "schiaparelli_img_url:   https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg\n",
      "syrtis_title:   Syrtis Major Hemisphere\n",
      "syrtis_img_url:   https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg\n",
      "valles_title:   Valles Marineris Hemisphere\n",
      "valles_img_url:   https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "# Selenium modules\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Run Google Chrome from Python.\n",
    "chrome_path = 'C:\\WebDrivers\\chromedriver.exe'\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "\n",
    "# Create mars_dict to collect the information along the way:\n",
    "mars_dict = {}\n",
    "\n",
    "#########################################################################\n",
    "# NASA Mars News\n",
    "#########################################################################\n",
    "\n",
    "# Open the webpage from Python.\n",
    "url = 'https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest'\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# Get the HTML for the website.\n",
    "html = driver.execute_script('return document.documentElement.outerHTML')\n",
    "\n",
    "#Close the driver\n",
    "driver.close()\n",
    "\n",
    "# This is the HTML for the webpage\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "page = soup.find('div', id = 'page')\n",
    "\n",
    "# Find all <li> tags\n",
    "all_lis = [li for li in page.ul.find_all('li')]\n",
    "\n",
    "# The latest news is in the first <li> tag.\n",
    "latest_li = all_lis[0]\n",
    "\n",
    "latest_news_title = latest_li.find('div', class_ = 'content_title').text\n",
    "latest_news_p = latest_li.find('div', class_ = 'article_teaser_body').text\n",
    "\n",
    "# latest news title and paragraph\n",
    "mars_dict[\"latest_news_title\"] = latest_news_title\n",
    "mars_dict[\"latest_news_p\"] = latest_news_p\n",
    "\n",
    "###################################################################################\n",
    "# JPL Mars Space Images - Featured Image\n",
    "###################################################################################\n",
    "\n",
    "# Run Google Chrome from Python.\n",
    "url_JPL_Mars = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "driver.get(url_JPL_Mars)\n",
    "\n",
    "# Get the HTML of the current page you are on.\n",
    "image_html = driver.page_source\n",
    "\n",
    "# This is the HTML for the webpage\n",
    "image_soup = BeautifulSoup(image_html, 'lxml')\n",
    "\n",
    "# Search for the tag of the full image, using link text.\n",
    "image_link = driver.find_element_by_link_text('FULL IMAGE')\n",
    "\n",
    "# Click on the link for the full image.\n",
    "image_link.click()\n",
    "\n",
    "# Wait for conpletion of previous action.\n",
    "try:\n",
    "    element = WebDriverWait(driver, 3).until(\n",
    "        EC.presence_of_element_located((By.LINK_TEXT, \"more info\"))\n",
    "    )\n",
    "    \n",
    "    # Click on the button for more info.\n",
    "    element.click()\n",
    "except:\n",
    "    driver.quit()\n",
    "\n",
    "# Get the HTML of the current page for the large picture.\n",
    "large_html = driver.page_source\n",
    "\n",
    "#Close the driver\n",
    "driver.close()\n",
    "\n",
    "# This is the HTML for the full picture webpage\n",
    "large_soup = BeautifulSoup(large_html, 'lxml')\n",
    "\n",
    "figure_tag = large_soup.find('figure', class_ = 'lede')\n",
    "base_url = 'https://www.jpl.nasa.gov'\n",
    "featured_image_url = base_url+figure_tag.a['href']\n",
    "\n",
    "mars_dict[\"featured_image_url\"] = featured_image_url\n",
    "\n",
    "############################################################################\n",
    "# Mars Weather\n",
    "############################################################################\n",
    "\n",
    "# Run Google Chrome from Python.\n",
    "url_weather = 'https://twitter.com/marswxreport?lang=en'\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "driver.get(url_weather)\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "# Get the HTML of the current page you are on.\n",
    "weather_html = driver.page_source\n",
    "\n",
    "#Close the driver\n",
    "driver.close()\n",
    "\n",
    "# This is the HTML for the Twitter webpage on Mars weather.\n",
    "weather_soup = BeautifulSoup(weather_html, 'lxml')\n",
    "\n",
    "div_tag = weather_soup.find('div', class_ = 'css-901oao r-hkyrab r-1qd0xha r-a023e6 r-16dba41 r-ad9z0x r-bcqeeo r-bnwqim r-qvutc0')\n",
    "mars_weather = div_tag.text\n",
    "\n",
    "mars_dict[\"mars_weather\"] = mars_weather\n",
    "\n",
    "#######################################################################\n",
    "# Mars Facts\n",
    "#######################################################################\n",
    "\n",
    "# Fetch the page at the url using \"requests\" module.\n",
    "facts_url = 'https://space-facts.com/mars/'\n",
    "response = requests.get(facts_url)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# Read all tables in the response into a list of dataframes\n",
    "dfs=pd.read_html(response.text)\n",
    "\n",
    "# Iterate through the DataFrames to access each table.\n",
    "facts_df = dfs[0]\n",
    "facts_df.columns = ['variable', 'value']\n",
    "facts = facts_df.set_index('variable')\n",
    "\n",
    "# Save DataFrame as HTML.\n",
    "facts_html_path = os.path.join(\".\", \"static\", \"facts.html\")\n",
    "facts.to_html(facts_html_path, encoding=\"utf-8\", index=True)\n",
    "\n",
    "mars_df = facts.T\n",
    "mars_df.columns = ['Equatorial Diameter', 'Polar Diameter', 'Mass', 'Moons',\n",
    "       'Orbit Distance', 'Orbit Period', 'Surface Temperature',\n",
    "       'First Record', 'Recorded By']\n",
    "\n",
    "# Save DataFrame as HTML.\n",
    "mars_html_path = os.path.join(\".\", \"static\", \"mars_facts.html\")\n",
    "mars_df.to_html(mars_html_path, encoding=\"utf-8\", index=False)\n",
    "\n",
    "#####################################################################\n",
    "# Mars Hemispheres\n",
    "#####################################################################\n",
    "\n",
    "# Run Google Chrome from Python.\n",
    "url_hemis = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "driver.get(url_hemis)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "hemisphere_image_urls = []\n",
    "#########################################################################\n",
    "\n",
    "# Cerberus Hemisphere\n",
    "\n",
    "# Search for the tag of the full image, using link text.\n",
    "cerberus_link = driver.find_element_by_link_text('Cerberus Hemisphere Enhanced')\n",
    "\n",
    "# Click on the link for the full image.\n",
    "cerberus_link.click()\n",
    "\n",
    "# Get the HTML of the current page.\n",
    "cerberus_hemis_html = driver.page_source\n",
    "\n",
    "# This is the HTML for the full picture webpage\n",
    "cerberus_soup = BeautifulSoup(cerberus_hemis_html, 'lxml')\n",
    "\n",
    "cerberus_title = cerberus_soup.find('h2', class_ = 'title').text[:-9]\n",
    "\n",
    "mars_dict[\"cerberus_title\"] = cerberus_title\n",
    "\n",
    "cerberus_div_img = cerberus_soup.find('div', class_ = 'downloads')\n",
    "cerberus_img_url = cerberus_div_img.a['href']\n",
    "\n",
    "mars_dict[\"cerberus_img_url\"] = cerberus_img_url\n",
    "\n",
    "# Dictionary\n",
    "cerberus_dict = {}\n",
    "cerberus_dict['title'] = cerberus_title\n",
    "cerberus_dict['img_url'] = cerberus_img_url\n",
    "\n",
    "hemisphere_image_urls.append(cerberus_dict)\n",
    "\n",
    "driver.back()\n",
    "######################################################################\n",
    "\n",
    "# Schiaparelli Hemisphere\n",
    "\n",
    "# Search for the tag.\n",
    "schiaparelli_link = driver.find_element_by_link_text('Schiaparelli Hemisphere Enhanced')\n",
    "\n",
    "# Click on the link.\n",
    "schiaparelli_link.click()\n",
    "\n",
    "# Get the HTML of the current page.\n",
    "schiaparelli_html = driver.page_source\n",
    "\n",
    "# This is the HTML for the current webpage\n",
    "schiaparelli_soup = BeautifulSoup(schiaparelli_html, 'lxml')\n",
    "\n",
    "schiaparelli_title = schiaparelli_soup.find('h2', class_ = 'title').text[:-9]\n",
    "\n",
    "mars_dict[\"schiaparelli_title\"] = schiaparelli_title\n",
    "\n",
    "schiaparelli_div_img = schiaparelli_soup.find('div', class_ = 'downloads')\n",
    "schiaparelli_img_url = schiaparelli_div_img.a['href']\n",
    "\n",
    "mars_dict[\"schiaparelli_img_url\"] = schiaparelli_img_url\n",
    "\n",
    "# Dictionary\n",
    "schiaparelli_dict = {}\n",
    "schiaparelli_dict['title'] = schiaparelli_title\n",
    "schiaparelli_dict['img_url'] = schiaparelli_img_url\n",
    "\n",
    "hemisphere_image_urls.append(schiaparelli_dict)\n",
    "\n",
    "driver.back()\n",
    "#########################################################################\n",
    "\n",
    "# Syrtis Major Hemisphere\n",
    "\n",
    "# Search for the tag.\n",
    "syrtis_link = driver.find_element_by_link_text('Syrtis Major Hemisphere Enhanced')\n",
    "\n",
    "# Click on the link.\n",
    "syrtis_link.click()\n",
    "\n",
    "# Get the HTML of the current page.\n",
    "syrtis_html = driver.page_source\n",
    "\n",
    "# This is the HTML for the current webpage\n",
    "syrtis_soup = BeautifulSoup(syrtis_html, 'lxml')\n",
    "\n",
    "syrtis_title = syrtis_soup.find('h2', class_ = 'title').text[:-9]\n",
    "\n",
    "mars_dict[\"syrtis_title\"] = syrtis_title\n",
    "\n",
    "syrtis_div_img = syrtis_soup.find('div', class_ = 'downloads')\n",
    "syrtis_img_url = syrtis_div_img.a['href']\n",
    "\n",
    "mars_dict[\"syrtis_img_url\"] = syrtis_img_url\n",
    "\n",
    "# Dictionary\n",
    "syrtis_dict = {}\n",
    "syrtis_dict['title'] = syrtis_title\n",
    "syrtis_dict['img_url'] = syrtis_img_url\n",
    "\n",
    "hemisphere_image_urls.append(syrtis_dict)\n",
    "\n",
    "driver.back()\n",
    "##################################################################\n",
    "\n",
    "# Valles Marineris Hemisphere Enhanced\n",
    "\n",
    "# Search for the tag.\n",
    "valles_link = driver.find_element_by_link_text('Valles Marineris Hemisphere Enhanced')\n",
    "\n",
    "# Click on the link.\n",
    "valles_link.click()\n",
    "\n",
    "# Get the HTML of the current page.\n",
    "valles_html = driver.page_source\n",
    "\n",
    "# This is the HTML for the current webpage\n",
    "valles_soup = BeautifulSoup(valles_html, 'lxml')\n",
    "\n",
    "valles_title = valles_soup.find('h2', class_ = 'title').text[:-9]\n",
    "\n",
    "mars_dict[\"valles_title\"] = valles_title\n",
    "\n",
    "valles_div_img = valles_soup.find('div', class_ = 'downloads')\n",
    "valles_img_url = valles_div_img.a['href']\n",
    "\n",
    "mars_dict[\"valles_img_url\"] = valles_img_url\n",
    "\n",
    "# Dictionary\n",
    "valles_dict = {}\n",
    "valles_dict['title'] = valles_title\n",
    "valles_dict['img_url'] = valles_img_url\n",
    "\n",
    "hemisphere_image_urls.append(valles_dict)\n",
    "\n",
    "driver.back()\n",
    "\n",
    "#Close the driver\n",
    "driver.close()\n",
    "\n",
    "# Print mars_dict\n",
    "for key, value in mars_dict.items():\n",
    "    print(f'{key}:   {value}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-PythonData] *",
   "language": "python",
   "name": "conda-env-.conda-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
